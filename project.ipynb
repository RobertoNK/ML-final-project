{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 3312)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "doc = pd.read_csv(\"Dataset/TrainData1.txt\", header= None, sep='\\t')\n",
    "doc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 3312)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2 = pd.read_csv(\"Dataset/TestData1.txt\",header = None, sep = \"\\t\")\n",
    "doc2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3302</th>\n",
       "      <th>3303</th>\n",
       "      <th>3304</th>\n",
       "      <th>3305</th>\n",
       "      <th>3306</th>\n",
       "      <th>3307</th>\n",
       "      <th>3308</th>\n",
       "      <th>3309</th>\n",
       "      <th>3310</th>\n",
       "      <th>3311</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.824254</td>\n",
       "      <td>1.923762</td>\n",
       "      <td>1.918450</td>\n",
       "      <td>2.352067e+00</td>\n",
       "      <td>3.117298e+00</td>\n",
       "      <td>3.051735</td>\n",
       "      <td>3.307977</td>\n",
       "      <td>3.430222e+00</td>\n",
       "      <td>3.586667</td>\n",
       "      <td>3.605218</td>\n",
       "      <td>...</td>\n",
       "      <td>1.836830e+00</td>\n",
       "      <td>1.855640</td>\n",
       "      <td>1.142389</td>\n",
       "      <td>2.054345</td>\n",
       "      <td>2.808224</td>\n",
       "      <td>1.782186</td>\n",
       "      <td>2.665703</td>\n",
       "      <td>2.468214</td>\n",
       "      <td>2.478581</td>\n",
       "      <td>2.308842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.904190</td>\n",
       "      <td>2.309524</td>\n",
       "      <td>2.152930</td>\n",
       "      <td>1.000000e+99</td>\n",
       "      <td>3.532368e+00</td>\n",
       "      <td>3.524866</td>\n",
       "      <td>3.677791</td>\n",
       "      <td>3.636671e+00</td>\n",
       "      <td>3.696868</td>\n",
       "      <td>3.716764</td>\n",
       "      <td>...</td>\n",
       "      <td>1.951532e+00</td>\n",
       "      <td>1.442323</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.127914</td>\n",
       "      <td>2.979658</td>\n",
       "      <td>1.961089</td>\n",
       "      <td>2.519027</td>\n",
       "      <td>2.054383</td>\n",
       "      <td>2.689903</td>\n",
       "      <td>2.090928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.750908</td>\n",
       "      <td>1.161068</td>\n",
       "      <td>1.017033</td>\n",
       "      <td>2.347993e+00</td>\n",
       "      <td>3.381889e+00</td>\n",
       "      <td>3.393096</td>\n",
       "      <td>3.509134</td>\n",
       "      <td>3.512466e+00</td>\n",
       "      <td>3.622203</td>\n",
       "      <td>3.603050</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.584105</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.945321</td>\n",
       "      <td>3.257004</td>\n",
       "      <td>1.965061</td>\n",
       "      <td>2.536066</td>\n",
       "      <td>1.449324</td>\n",
       "      <td>2.605230</td>\n",
       "      <td>1.368659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.809383</td>\n",
       "      <td>1.912355</td>\n",
       "      <td>1.856940</td>\n",
       "      <td>2.498944e+00</td>\n",
       "      <td>3.289406e+00</td>\n",
       "      <td>3.371232</td>\n",
       "      <td>3.541995</td>\n",
       "      <td>1.000000e+99</td>\n",
       "      <td>3.473179</td>\n",
       "      <td>3.628930</td>\n",
       "      <td>...</td>\n",
       "      <td>1.869965e+00</td>\n",
       "      <td>1.481658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.155032</td>\n",
       "      <td>3.270371</td>\n",
       "      <td>1.928473</td>\n",
       "      <td>2.618074</td>\n",
       "      <td>2.154013</td>\n",
       "      <td>2.530046</td>\n",
       "      <td>2.185514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.893561</td>\n",
       "      <td>2.094192</td>\n",
       "      <td>1.881271</td>\n",
       "      <td>2.785707e+00</td>\n",
       "      <td>3.344339e+00</td>\n",
       "      <td>3.274417</td>\n",
       "      <td>3.485872</td>\n",
       "      <td>3.516527e+00</td>\n",
       "      <td>3.642358</td>\n",
       "      <td>3.688235</td>\n",
       "      <td>...</td>\n",
       "      <td>1.480725e+00</td>\n",
       "      <td>1.510545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.094192</td>\n",
       "      <td>3.246666</td>\n",
       "      <td>1.824516</td>\n",
       "      <td>2.562317</td>\n",
       "      <td>1.942256</td>\n",
       "      <td>2.598517</td>\n",
       "      <td>1.764624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.841385</td>\n",
       "      <td>1.203848</td>\n",
       "      <td>1.015360</td>\n",
       "      <td>2.289634e+00</td>\n",
       "      <td>3.108612e+00</td>\n",
       "      <td>3.066139</td>\n",
       "      <td>3.410717</td>\n",
       "      <td>3.487736e+00</td>\n",
       "      <td>3.641201</td>\n",
       "      <td>3.664932</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.717421</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.135737</td>\n",
       "      <td>3.021475</td>\n",
       "      <td>2.054345</td>\n",
       "      <td>2.601995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.541554</td>\n",
       "      <td>2.089870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.904243</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.701741</td>\n",
       "      <td>2.048752e+00</td>\n",
       "      <td>3.429904e+00</td>\n",
       "      <td>3.443864</td>\n",
       "      <td>3.630035</td>\n",
       "      <td>3.447663e+00</td>\n",
       "      <td>3.543115</td>\n",
       "      <td>3.584522</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+99</td>\n",
       "      <td>1.672929</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.321039</td>\n",
       "      <td>2.814061</td>\n",
       "      <td>1.831230</td>\n",
       "      <td>2.752087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.796713</td>\n",
       "      <td>2.131137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.879258</td>\n",
       "      <td>1.067815</td>\n",
       "      <td>1.554852</td>\n",
       "      <td>1.872739e+00</td>\n",
       "      <td>3.256246e+00</td>\n",
       "      <td>3.224574</td>\n",
       "      <td>3.414243</td>\n",
       "      <td>3.511133e+00</td>\n",
       "      <td>3.631307</td>\n",
       "      <td>3.591646</td>\n",
       "      <td>...</td>\n",
       "      <td>1.976717e+00</td>\n",
       "      <td>1.592288</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.984032</td>\n",
       "      <td>2.875709</td>\n",
       "      <td>1.361350</td>\n",
       "      <td>2.587857</td>\n",
       "      <td>2.151186</td>\n",
       "      <td>2.360025</td>\n",
       "      <td>1.863263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.898461</td>\n",
       "      <td>1.542078</td>\n",
       "      <td>1.566437</td>\n",
       "      <td>2.291125e+00</td>\n",
       "      <td>1.000000e+99</td>\n",
       "      <td>3.487488</td>\n",
       "      <td>3.659641</td>\n",
       "      <td>3.380352e+00</td>\n",
       "      <td>3.512384</td>\n",
       "      <td>3.640448</td>\n",
       "      <td>...</td>\n",
       "      <td>1.996030e+00</td>\n",
       "      <td>1.791971</td>\n",
       "      <td>1.832317</td>\n",
       "      <td>2.228862</td>\n",
       "      <td>2.857839</td>\n",
       "      <td>2.049761</td>\n",
       "      <td>2.583754</td>\n",
       "      <td>2.359171</td>\n",
       "      <td>2.233985</td>\n",
       "      <td>2.094087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.861195</td>\n",
       "      <td>2.333064</td>\n",
       "      <td>2.299202</td>\n",
       "      <td>2.626987e+00</td>\n",
       "      <td>3.400348e+00</td>\n",
       "      <td>3.366804</td>\n",
       "      <td>3.525154</td>\n",
       "      <td>3.597381e+00</td>\n",
       "      <td>3.686170</td>\n",
       "      <td>3.677235</td>\n",
       "      <td>...</td>\n",
       "      <td>1.617420e+00</td>\n",
       "      <td>1.768268</td>\n",
       "      <td>1.081707</td>\n",
       "      <td>2.042339</td>\n",
       "      <td>3.166306</td>\n",
       "      <td>2.073095</td>\n",
       "      <td>2.505313</td>\n",
       "      <td>2.013553</td>\n",
       "      <td>2.916849</td>\n",
       "      <td>2.080482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 3312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2             3             4         5     \\\n",
       "0  3.824254  1.923762  1.918450  2.352067e+00  3.117298e+00  3.051735   \n",
       "1  3.904190  2.309524  2.152930  1.000000e+99  3.532368e+00  3.524866   \n",
       "2  3.750908  1.161068  1.017033  2.347993e+00  3.381889e+00  3.393096   \n",
       "3  3.809383  1.912355  1.856940  2.498944e+00  3.289406e+00  3.371232   \n",
       "4  3.893561  2.094192  1.881271  2.785707e+00  3.344339e+00  3.274417   \n",
       "5  3.841385  1.203848  1.015360  2.289634e+00  3.108612e+00  3.066139   \n",
       "6  3.904243  1.000000  1.701741  2.048752e+00  3.429904e+00  3.443864   \n",
       "7  3.879258  1.067815  1.554852  1.872739e+00  3.256246e+00  3.224574   \n",
       "8  3.898461  1.542078  1.566437  2.291125e+00  1.000000e+99  3.487488   \n",
       "9  3.861195  2.333064  2.299202  2.626987e+00  3.400348e+00  3.366804   \n",
       "\n",
       "       6             7         8         9     ...          3302      3303  \\\n",
       "0  3.307977  3.430222e+00  3.586667  3.605218  ...  1.836830e+00  1.855640   \n",
       "1  3.677791  3.636671e+00  3.696868  3.716764  ...  1.951532e+00  1.442323   \n",
       "2  3.509134  3.512466e+00  3.622203  3.603050  ...  1.000000e+00  1.584105   \n",
       "3  3.541995  1.000000e+99  3.473179  3.628930  ...  1.869965e+00  1.481658   \n",
       "4  3.485872  3.516527e+00  3.642358  3.688235  ...  1.480725e+00  1.510545   \n",
       "5  3.410717  3.487736e+00  3.641201  3.664932  ...  1.000000e+00  1.717421   \n",
       "6  3.630035  3.447663e+00  3.543115  3.584522  ...  1.000000e+99  1.672929   \n",
       "7  3.414243  3.511133e+00  3.631307  3.591646  ...  1.976717e+00  1.592288   \n",
       "8  3.659641  3.380352e+00  3.512384  3.640448  ...  1.996030e+00  1.791971   \n",
       "9  3.525154  3.597381e+00  3.686170  3.677235  ...  1.617420e+00  1.768268   \n",
       "\n",
       "       3304      3305      3306      3307      3308      3309      3310  \\\n",
       "0  1.142389  2.054345  2.808224  1.782186  2.665703  2.468214  2.478581   \n",
       "1  1.000000  2.127914  2.979658  1.961089  2.519027  2.054383  2.689903   \n",
       "2  1.000000  1.945321  3.257004  1.965061  2.536066  1.449324  2.605230   \n",
       "3  1.000000  2.155032  3.270371  1.928473  2.618074  2.154013  2.530046   \n",
       "4  1.000000  2.094192  3.246666  1.824516  2.562317  1.942256  2.598517   \n",
       "5  1.000000  2.135737  3.021475  2.054345  2.601995  1.000000  2.541554   \n",
       "6  1.000000  2.321039  2.814061  1.831230  2.752087  1.000000  1.796713   \n",
       "7  1.000000  1.984032  2.875709  1.361350  2.587857  2.151186  2.360025   \n",
       "8  1.832317  2.228862  2.857839  2.049761  2.583754  2.359171  2.233985   \n",
       "9  1.081707  2.042339  3.166306  2.073095  2.505313  2.013553  2.916849   \n",
       "\n",
       "       3311  \n",
       "0  2.308842  \n",
       "1  2.090928  \n",
       "2  1.368659  \n",
       "3  2.185514  \n",
       "4  1.764624  \n",
       "5  2.089870  \n",
       "6  2.131137  \n",
       "7  1.863263  \n",
       "8  2.094087  \n",
       "9  2.080482  \n",
       "\n",
       "[10 rows x 3312 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern2 = re.compile(r'[+|-]*\\d\\.\\d+[e|E][+|-][^00]\\d+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "[rows, columns] = doc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3312"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "        \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(0, rows):\n",
    "    for col in range(0,columns):\n",
    "        if doc.iloc[row][col] > 10:\n",
    "            doc.iloc[row][col] = np.nan\n",
    "        \n",
    "\n",
    "new = doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(0, rows):\n",
    "    for col in range(0,columns):\n",
    "        if doc.iloc[row][col] > 10:\n",
    "            print(\"row\",row)\n",
    "            print(\"col\",col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy = \"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "medians = doc.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3312"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(medians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.498469525596855"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medians[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3302</th>\n",
       "      <th>3303</th>\n",
       "      <th>3304</th>\n",
       "      <th>3305</th>\n",
       "      <th>3306</th>\n",
       "      <th>3307</th>\n",
       "      <th>3308</th>\n",
       "      <th>3309</th>\n",
       "      <th>3310</th>\n",
       "      <th>3311</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.824254</td>\n",
       "      <td>1.923762</td>\n",
       "      <td>1.918450</td>\n",
       "      <td>2.352067</td>\n",
       "      <td>3.117298</td>\n",
       "      <td>3.051735</td>\n",
       "      <td>3.307977</td>\n",
       "      <td>3.430222</td>\n",
       "      <td>3.586667</td>\n",
       "      <td>3.605218</td>\n",
       "      <td>...</td>\n",
       "      <td>1.836830</td>\n",
       "      <td>1.855640</td>\n",
       "      <td>1.142389</td>\n",
       "      <td>2.054345</td>\n",
       "      <td>2.808224</td>\n",
       "      <td>1.782186</td>\n",
       "      <td>2.665703</td>\n",
       "      <td>2.468214</td>\n",
       "      <td>2.478581</td>\n",
       "      <td>2.308842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.904190</td>\n",
       "      <td>2.309524</td>\n",
       "      <td>2.152930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.532368</td>\n",
       "      <td>3.524866</td>\n",
       "      <td>3.677791</td>\n",
       "      <td>3.636671</td>\n",
       "      <td>3.696868</td>\n",
       "      <td>3.716764</td>\n",
       "      <td>...</td>\n",
       "      <td>1.951532</td>\n",
       "      <td>1.442323</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.127914</td>\n",
       "      <td>2.979658</td>\n",
       "      <td>1.961089</td>\n",
       "      <td>2.519027</td>\n",
       "      <td>2.054383</td>\n",
       "      <td>2.689903</td>\n",
       "      <td>2.090928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.750908</td>\n",
       "      <td>1.161068</td>\n",
       "      <td>1.017033</td>\n",
       "      <td>2.347993</td>\n",
       "      <td>3.381889</td>\n",
       "      <td>3.393096</td>\n",
       "      <td>3.509134</td>\n",
       "      <td>3.512466</td>\n",
       "      <td>3.622203</td>\n",
       "      <td>3.603050</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.584105</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.945321</td>\n",
       "      <td>3.257004</td>\n",
       "      <td>1.965061</td>\n",
       "      <td>2.536066</td>\n",
       "      <td>1.449324</td>\n",
       "      <td>2.605230</td>\n",
       "      <td>1.368659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.809383</td>\n",
       "      <td>1.912355</td>\n",
       "      <td>1.856940</td>\n",
       "      <td>2.498944</td>\n",
       "      <td>3.289406</td>\n",
       "      <td>3.371232</td>\n",
       "      <td>3.541995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.473179</td>\n",
       "      <td>3.628930</td>\n",
       "      <td>...</td>\n",
       "      <td>1.869965</td>\n",
       "      <td>1.481658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.155032</td>\n",
       "      <td>3.270371</td>\n",
       "      <td>1.928473</td>\n",
       "      <td>2.618074</td>\n",
       "      <td>2.154013</td>\n",
       "      <td>2.530046</td>\n",
       "      <td>2.185514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.893561</td>\n",
       "      <td>2.094192</td>\n",
       "      <td>1.881271</td>\n",
       "      <td>2.785707</td>\n",
       "      <td>3.344339</td>\n",
       "      <td>3.274417</td>\n",
       "      <td>3.485872</td>\n",
       "      <td>3.516527</td>\n",
       "      <td>3.642358</td>\n",
       "      <td>3.688235</td>\n",
       "      <td>...</td>\n",
       "      <td>1.480725</td>\n",
       "      <td>1.510545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.094192</td>\n",
       "      <td>3.246666</td>\n",
       "      <td>1.824516</td>\n",
       "      <td>2.562317</td>\n",
       "      <td>1.942256</td>\n",
       "      <td>2.598517</td>\n",
       "      <td>1.764624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.841385</td>\n",
       "      <td>1.203848</td>\n",
       "      <td>1.015360</td>\n",
       "      <td>2.289634</td>\n",
       "      <td>3.108612</td>\n",
       "      <td>3.066139</td>\n",
       "      <td>3.410717</td>\n",
       "      <td>3.487736</td>\n",
       "      <td>3.641201</td>\n",
       "      <td>3.664932</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.717421</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.135737</td>\n",
       "      <td>3.021475</td>\n",
       "      <td>2.054345</td>\n",
       "      <td>2.601995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.541554</td>\n",
       "      <td>2.089870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.904243</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.701741</td>\n",
       "      <td>2.048752</td>\n",
       "      <td>3.429904</td>\n",
       "      <td>3.443864</td>\n",
       "      <td>3.630035</td>\n",
       "      <td>3.447663</td>\n",
       "      <td>3.543115</td>\n",
       "      <td>3.584522</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.672929</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.321039</td>\n",
       "      <td>2.814061</td>\n",
       "      <td>1.831230</td>\n",
       "      <td>2.752087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.796713</td>\n",
       "      <td>2.131137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.879258</td>\n",
       "      <td>1.067815</td>\n",
       "      <td>1.554852</td>\n",
       "      <td>1.872739</td>\n",
       "      <td>3.256246</td>\n",
       "      <td>3.224574</td>\n",
       "      <td>3.414243</td>\n",
       "      <td>3.511133</td>\n",
       "      <td>3.631307</td>\n",
       "      <td>3.591646</td>\n",
       "      <td>...</td>\n",
       "      <td>1.976717</td>\n",
       "      <td>1.592288</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.984032</td>\n",
       "      <td>2.875709</td>\n",
       "      <td>1.361350</td>\n",
       "      <td>2.587857</td>\n",
       "      <td>2.151186</td>\n",
       "      <td>2.360025</td>\n",
       "      <td>1.863263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.898461</td>\n",
       "      <td>1.542078</td>\n",
       "      <td>1.566437</td>\n",
       "      <td>2.291125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.487488</td>\n",
       "      <td>3.659641</td>\n",
       "      <td>3.380352</td>\n",
       "      <td>3.512384</td>\n",
       "      <td>3.640448</td>\n",
       "      <td>...</td>\n",
       "      <td>1.996030</td>\n",
       "      <td>1.791971</td>\n",
       "      <td>1.832317</td>\n",
       "      <td>2.228862</td>\n",
       "      <td>2.857839</td>\n",
       "      <td>2.049761</td>\n",
       "      <td>2.583754</td>\n",
       "      <td>2.359171</td>\n",
       "      <td>2.233985</td>\n",
       "      <td>2.094087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.861195</td>\n",
       "      <td>2.333064</td>\n",
       "      <td>2.299202</td>\n",
       "      <td>2.626987</td>\n",
       "      <td>3.400348</td>\n",
       "      <td>3.366804</td>\n",
       "      <td>3.525154</td>\n",
       "      <td>3.597381</td>\n",
       "      <td>3.686170</td>\n",
       "      <td>3.677235</td>\n",
       "      <td>...</td>\n",
       "      <td>1.617420</td>\n",
       "      <td>1.768268</td>\n",
       "      <td>1.081707</td>\n",
       "      <td>2.042339</td>\n",
       "      <td>3.166306</td>\n",
       "      <td>2.073095</td>\n",
       "      <td>2.505313</td>\n",
       "      <td>2.013553</td>\n",
       "      <td>2.916849</td>\n",
       "      <td>2.080482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.921344</td>\n",
       "      <td>2.051538</td>\n",
       "      <td>2.068779</td>\n",
       "      <td>2.452139</td>\n",
       "      <td>3.332721</td>\n",
       "      <td>3.313979</td>\n",
       "      <td>3.492541</td>\n",
       "      <td>3.221477</td>\n",
       "      <td>3.240557</td>\n",
       "      <td>3.379784</td>\n",
       "      <td>...</td>\n",
       "      <td>2.151891</td>\n",
       "      <td>2.089940</td>\n",
       "      <td>1.738622</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.619417</td>\n",
       "      <td>2.191814</td>\n",
       "      <td>2.779236</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.071182</td>\n",
       "      <td>2.332014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.820743</td>\n",
       "      <td>2.371327</td>\n",
       "      <td>2.291091</td>\n",
       "      <td>2.770775</td>\n",
       "      <td>3.501755</td>\n",
       "      <td>3.524519</td>\n",
       "      <td>3.560045</td>\n",
       "      <td>3.539958</td>\n",
       "      <td>3.672477</td>\n",
       "      <td>3.595527</td>\n",
       "      <td>...</td>\n",
       "      <td>1.384980</td>\n",
       "      <td>1.397853</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.214314</td>\n",
       "      <td>3.211612</td>\n",
       "      <td>1.898698</td>\n",
       "      <td>2.455066</td>\n",
       "      <td>1.867850</td>\n",
       "      <td>2.832685</td>\n",
       "      <td>1.770852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.895507</td>\n",
       "      <td>2.153022</td>\n",
       "      <td>1.991226</td>\n",
       "      <td>2.585043</td>\n",
       "      <td>3.592847</td>\n",
       "      <td>3.663589</td>\n",
       "      <td>3.684571</td>\n",
       "      <td>3.623747</td>\n",
       "      <td>3.696136</td>\n",
       "      <td>3.725038</td>\n",
       "      <td>...</td>\n",
       "      <td>1.350442</td>\n",
       "      <td>1.416641</td>\n",
       "      <td>1.512551</td>\n",
       "      <td>2.350752</td>\n",
       "      <td>3.419290</td>\n",
       "      <td>1.722963</td>\n",
       "      <td>2.401245</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.831134</td>\n",
       "      <td>2.041314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.814212</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.526598</td>\n",
       "      <td>2.389042</td>\n",
       "      <td>3.595472</td>\n",
       "      <td>3.613147</td>\n",
       "      <td>3.663301</td>\n",
       "      <td>3.514882</td>\n",
       "      <td>3.665123</td>\n",
       "      <td>3.636483</td>\n",
       "      <td>...</td>\n",
       "      <td>1.763203</td>\n",
       "      <td>1.561101</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.003116</td>\n",
       "      <td>3.343265</td>\n",
       "      <td>1.856970</td>\n",
       "      <td>2.621716</td>\n",
       "      <td>1.310693</td>\n",
       "      <td>2.586013</td>\n",
       "      <td>1.803184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.868812</td>\n",
       "      <td>1.646306</td>\n",
       "      <td>1.644636</td>\n",
       "      <td>2.181086</td>\n",
       "      <td>3.153080</td>\n",
       "      <td>3.164950</td>\n",
       "      <td>3.434115</td>\n",
       "      <td>3.444213</td>\n",
       "      <td>3.570820</td>\n",
       "      <td>3.639826</td>\n",
       "      <td>...</td>\n",
       "      <td>1.836039</td>\n",
       "      <td>1.842703</td>\n",
       "      <td>1.167170</td>\n",
       "      <td>2.024650</td>\n",
       "      <td>3.120689</td>\n",
       "      <td>1.967454</td>\n",
       "      <td>2.575978</td>\n",
       "      <td>2.144870</td>\n",
       "      <td>2.315708</td>\n",
       "      <td>2.014814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.863111</td>\n",
       "      <td>2.300726</td>\n",
       "      <td>2.301008</td>\n",
       "      <td>2.763630</td>\n",
       "      <td>3.433169</td>\n",
       "      <td>3.435089</td>\n",
       "      <td>3.537763</td>\n",
       "      <td>3.490465</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.660884</td>\n",
       "      <td>...</td>\n",
       "      <td>1.810300</td>\n",
       "      <td>1.735319</td>\n",
       "      <td>1.676511</td>\n",
       "      <td>2.258913</td>\n",
       "      <td>3.289366</td>\n",
       "      <td>1.830973</td>\n",
       "      <td>2.543944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.695149</td>\n",
       "      <td>2.036848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.809824</td>\n",
       "      <td>2.272746</td>\n",
       "      <td>2.135005</td>\n",
       "      <td>2.619771</td>\n",
       "      <td>3.310107</td>\n",
       "      <td>3.168209</td>\n",
       "      <td>3.409158</td>\n",
       "      <td>3.576675</td>\n",
       "      <td>3.693858</td>\n",
       "      <td>3.616255</td>\n",
       "      <td>...</td>\n",
       "      <td>1.134496</td>\n",
       "      <td>1.565021</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.247359</td>\n",
       "      <td>3.145498</td>\n",
       "      <td>1.739889</td>\n",
       "      <td>2.465056</td>\n",
       "      <td>2.409172</td>\n",
       "      <td>2.806560</td>\n",
       "      <td>1.834166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.933567</td>\n",
       "      <td>1.750277</td>\n",
       "      <td>1.897242</td>\n",
       "      <td>2.223002</td>\n",
       "      <td>3.384309</td>\n",
       "      <td>3.440791</td>\n",
       "      <td>3.578622</td>\n",
       "      <td>3.380562</td>\n",
       "      <td>3.517615</td>\n",
       "      <td>3.552477</td>\n",
       "      <td>...</td>\n",
       "      <td>2.153388</td>\n",
       "      <td>2.253241</td>\n",
       "      <td>1.798858</td>\n",
       "      <td>2.316599</td>\n",
       "      <td>2.983811</td>\n",
       "      <td>1.949048</td>\n",
       "      <td>2.781030</td>\n",
       "      <td>2.052925</td>\n",
       "      <td>2.039890</td>\n",
       "      <td>2.374418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.850494</td>\n",
       "      <td>2.422114</td>\n",
       "      <td>2.405107</td>\n",
       "      <td>2.939859</td>\n",
       "      <td>3.596283</td>\n",
       "      <td>3.509580</td>\n",
       "      <td>3.548588</td>\n",
       "      <td>3.607209</td>\n",
       "      <td>3.701704</td>\n",
       "      <td>3.645704</td>\n",
       "      <td>...</td>\n",
       "      <td>2.136879</td>\n",
       "      <td>1.864985</td>\n",
       "      <td>1.670802</td>\n",
       "      <td>2.279279</td>\n",
       "      <td>3.299403</td>\n",
       "      <td>2.205123</td>\n",
       "      <td>2.654013</td>\n",
       "      <td>1.427648</td>\n",
       "      <td>2.889845</td>\n",
       "      <td>2.028653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.845383</td>\n",
       "      <td>2.148819</td>\n",
       "      <td>2.104453</td>\n",
       "      <td>2.713087</td>\n",
       "      <td>3.262192</td>\n",
       "      <td>3.195509</td>\n",
       "      <td>3.447792</td>\n",
       "      <td>3.278127</td>\n",
       "      <td>3.475588</td>\n",
       "      <td>3.678231</td>\n",
       "      <td>...</td>\n",
       "      <td>1.962275</td>\n",
       "      <td>1.629206</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.266467</td>\n",
       "      <td>3.209866</td>\n",
       "      <td>1.735519</td>\n",
       "      <td>2.592343</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.468259</td>\n",
       "      <td>2.088632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 3312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6     \\\n",
       "0   3.824254  1.923762  1.918450  2.352067  3.117298  3.051735  3.307977   \n",
       "1   3.904190  2.309524  2.152930       NaN  3.532368  3.524866  3.677791   \n",
       "2   3.750908  1.161068  1.017033  2.347993  3.381889  3.393096  3.509134   \n",
       "3   3.809383  1.912355  1.856940  2.498944  3.289406  3.371232  3.541995   \n",
       "4   3.893561  2.094192  1.881271  2.785707  3.344339  3.274417  3.485872   \n",
       "5   3.841385  1.203848  1.015360  2.289634  3.108612  3.066139  3.410717   \n",
       "6   3.904243  1.000000  1.701741  2.048752  3.429904  3.443864  3.630035   \n",
       "7   3.879258  1.067815  1.554852  1.872739  3.256246  3.224574  3.414243   \n",
       "8   3.898461  1.542078  1.566437  2.291125       NaN  3.487488  3.659641   \n",
       "9   3.861195  2.333064  2.299202  2.626987  3.400348  3.366804  3.525154   \n",
       "10  3.921344  2.051538  2.068779  2.452139  3.332721  3.313979  3.492541   \n",
       "11  3.820743  2.371327  2.291091  2.770775  3.501755  3.524519  3.560045   \n",
       "12  3.895507  2.153022  1.991226  2.585043  3.592847  3.663589  3.684571   \n",
       "13  3.814212  1.000000  1.526598  2.389042  3.595472  3.613147  3.663301   \n",
       "14  3.868812  1.646306  1.644636  2.181086  3.153080  3.164950  3.434115   \n",
       "15  3.863111  2.300726  2.301008  2.763630  3.433169  3.435089  3.537763   \n",
       "16  3.809824  2.272746  2.135005  2.619771  3.310107  3.168209  3.409158   \n",
       "17  3.933567  1.750277  1.897242  2.223002  3.384309  3.440791  3.578622   \n",
       "18  3.850494  2.422114  2.405107  2.939859  3.596283  3.509580  3.548588   \n",
       "19  3.845383  2.148819  2.104453  2.713087  3.262192  3.195509  3.447792   \n",
       "\n",
       "        7         8         9     ...      3302      3303      3304      3305  \\\n",
       "0   3.430222  3.586667  3.605218  ...  1.836830  1.855640  1.142389  2.054345   \n",
       "1   3.636671  3.696868  3.716764  ...  1.951532  1.442323  1.000000  2.127914   \n",
       "2   3.512466  3.622203  3.603050  ...  1.000000  1.584105  1.000000  1.945321   \n",
       "3        NaN  3.473179  3.628930  ...  1.869965  1.481658  1.000000  2.155032   \n",
       "4   3.516527  3.642358  3.688235  ...  1.480725  1.510545  1.000000  2.094192   \n",
       "5   3.487736  3.641201  3.664932  ...  1.000000  1.717421  1.000000  2.135737   \n",
       "6   3.447663  3.543115  3.584522  ...       NaN  1.672929  1.000000  2.321039   \n",
       "7   3.511133  3.631307  3.591646  ...  1.976717  1.592288  1.000000  1.984032   \n",
       "8   3.380352  3.512384  3.640448  ...  1.996030  1.791971  1.832317  2.228862   \n",
       "9   3.597381  3.686170  3.677235  ...  1.617420  1.768268  1.081707  2.042339   \n",
       "10  3.221477  3.240557  3.379784  ...  2.151891  2.089940  1.738622       NaN   \n",
       "11  3.539958  3.672477  3.595527  ...  1.384980  1.397853  1.000000  2.214314   \n",
       "12  3.623747  3.696136  3.725038  ...  1.350442  1.416641  1.512551  2.350752   \n",
       "13  3.514882  3.665123  3.636483  ...  1.763203  1.561101  1.000000  2.003116   \n",
       "14  3.444213  3.570820  3.639826  ...  1.836039  1.842703  1.167170  2.024650   \n",
       "15  3.490465       NaN  3.660884  ...  1.810300  1.735319  1.676511  2.258913   \n",
       "16  3.576675  3.693858  3.616255  ...  1.134496  1.565021  1.000000  2.247359   \n",
       "17  3.380562  3.517615  3.552477  ...  2.153388  2.253241  1.798858  2.316599   \n",
       "18  3.607209  3.701704  3.645704  ...  2.136879  1.864985  1.670802  2.279279   \n",
       "19  3.278127  3.475588  3.678231  ...  1.962275  1.629206  1.000000  2.266467   \n",
       "\n",
       "        3306      3307      3308      3309      3310      3311  \n",
       "0   2.808224  1.782186  2.665703  2.468214  2.478581  2.308842  \n",
       "1   2.979658  1.961089  2.519027  2.054383  2.689903  2.090928  \n",
       "2   3.257004  1.965061  2.536066  1.449324  2.605230  1.368659  \n",
       "3   3.270371  1.928473  2.618074  2.154013  2.530046  2.185514  \n",
       "4   3.246666  1.824516  2.562317  1.942256  2.598517  1.764624  \n",
       "5   3.021475  2.054345  2.601995  1.000000  2.541554  2.089870  \n",
       "6   2.814061  1.831230  2.752087  1.000000  1.796713  2.131137  \n",
       "7   2.875709  1.361350  2.587857  2.151186  2.360025  1.863263  \n",
       "8   2.857839  2.049761  2.583754  2.359171  2.233985  2.094087  \n",
       "9   3.166306  2.073095  2.505313  2.013553  2.916849  2.080482  \n",
       "10  2.619417  2.191814  2.779236  1.000000  2.071182  2.332014  \n",
       "11  3.211612  1.898698  2.455066  1.867850  2.832685  1.770852  \n",
       "12  3.419290  1.722963  2.401245  1.000000  2.831134  2.041314  \n",
       "13  3.343265  1.856970  2.621716  1.310693  2.586013  1.803184  \n",
       "14  3.120689  1.967454  2.575978  2.144870  2.315708  2.014814  \n",
       "15  3.289366  1.830973  2.543944       NaN  2.695149  2.036848  \n",
       "16  3.145498  1.739889  2.465056  2.409172  2.806560  1.834166  \n",
       "17  2.983811  1.949048  2.781030  2.052925  2.039890  2.374418  \n",
       "18  3.299403  2.205123  2.654013  1.427648  2.889845  2.028653  \n",
       "19  3.209866  1.735519  2.592343  1.000000  2.468259  2.088632  \n",
       "\n",
       "[20 rows x 3312 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer.fit(new)\n",
    "new_2 = imputer.transform(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.82425408, 1.92376196, 1.91844974, ..., 2.46821436, 2.47858092,\n",
       "        2.30884176],\n",
       "       [3.90418953, 2.30952371, 2.15293014, ..., 2.05438321, 2.6899035 ,\n",
       "        2.09092785],\n",
       "       [3.75090779, 1.16106839, 1.01703334, ..., 1.44932409, 2.6052296 ,\n",
       "        1.36865871],\n",
       "       ...,\n",
       "       [3.86019841, 2.09777773, 1.89307773, ..., 1.        , 2.28254281,\n",
       "        2.05570317],\n",
       "       [3.90710165, 1.        , 1.47363293, ..., 1.        , 1.96848295,\n",
       "        2.31850158],\n",
       "       [3.76386656, 2.2811925 , 2.19917903, ..., 1.47334096, 3.00529208,\n",
       "        2.23279288]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_3 = pd.DataFrame(new_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3302</th>\n",
       "      <th>3303</th>\n",
       "      <th>3304</th>\n",
       "      <th>3305</th>\n",
       "      <th>3306</th>\n",
       "      <th>3307</th>\n",
       "      <th>3308</th>\n",
       "      <th>3309</th>\n",
       "      <th>3310</th>\n",
       "      <th>3311</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.824254</td>\n",
       "      <td>1.923762</td>\n",
       "      <td>1.918450</td>\n",
       "      <td>2.352067</td>\n",
       "      <td>3.117298</td>\n",
       "      <td>3.051735</td>\n",
       "      <td>3.307977</td>\n",
       "      <td>3.430222</td>\n",
       "      <td>3.586667</td>\n",
       "      <td>3.605218</td>\n",
       "      <td>...</td>\n",
       "      <td>1.836830</td>\n",
       "      <td>1.855640</td>\n",
       "      <td>1.142389</td>\n",
       "      <td>2.054345</td>\n",
       "      <td>2.808224</td>\n",
       "      <td>1.782186</td>\n",
       "      <td>2.665703</td>\n",
       "      <td>2.468214</td>\n",
       "      <td>2.478581</td>\n",
       "      <td>2.308842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.904190</td>\n",
       "      <td>2.309524</td>\n",
       "      <td>2.152930</td>\n",
       "      <td>2.439439</td>\n",
       "      <td>3.532368</td>\n",
       "      <td>3.524866</td>\n",
       "      <td>3.677791</td>\n",
       "      <td>3.636671</td>\n",
       "      <td>3.696868</td>\n",
       "      <td>3.716764</td>\n",
       "      <td>...</td>\n",
       "      <td>1.951532</td>\n",
       "      <td>1.442323</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.127914</td>\n",
       "      <td>2.979658</td>\n",
       "      <td>1.961089</td>\n",
       "      <td>2.519027</td>\n",
       "      <td>2.054383</td>\n",
       "      <td>2.689903</td>\n",
       "      <td>2.090928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.750908</td>\n",
       "      <td>1.161068</td>\n",
       "      <td>1.017033</td>\n",
       "      <td>2.347993</td>\n",
       "      <td>3.381889</td>\n",
       "      <td>3.393096</td>\n",
       "      <td>3.509134</td>\n",
       "      <td>3.512466</td>\n",
       "      <td>3.622203</td>\n",
       "      <td>3.603050</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.584105</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.945321</td>\n",
       "      <td>3.257004</td>\n",
       "      <td>1.965061</td>\n",
       "      <td>2.536066</td>\n",
       "      <td>1.449324</td>\n",
       "      <td>2.605230</td>\n",
       "      <td>1.368659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.809383</td>\n",
       "      <td>1.912355</td>\n",
       "      <td>1.856940</td>\n",
       "      <td>2.498944</td>\n",
       "      <td>3.289406</td>\n",
       "      <td>3.371232</td>\n",
       "      <td>3.541995</td>\n",
       "      <td>3.498470</td>\n",
       "      <td>3.473179</td>\n",
       "      <td>3.628930</td>\n",
       "      <td>...</td>\n",
       "      <td>1.869965</td>\n",
       "      <td>1.481658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.155032</td>\n",
       "      <td>3.270371</td>\n",
       "      <td>1.928473</td>\n",
       "      <td>2.618074</td>\n",
       "      <td>2.154013</td>\n",
       "      <td>2.530046</td>\n",
       "      <td>2.185514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.893561</td>\n",
       "      <td>2.094192</td>\n",
       "      <td>1.881271</td>\n",
       "      <td>2.785707</td>\n",
       "      <td>3.344339</td>\n",
       "      <td>3.274417</td>\n",
       "      <td>3.485872</td>\n",
       "      <td>3.516527</td>\n",
       "      <td>3.642358</td>\n",
       "      <td>3.688235</td>\n",
       "      <td>...</td>\n",
       "      <td>1.480725</td>\n",
       "      <td>1.510545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.094192</td>\n",
       "      <td>3.246666</td>\n",
       "      <td>1.824516</td>\n",
       "      <td>2.562317</td>\n",
       "      <td>1.942256</td>\n",
       "      <td>2.598517</td>\n",
       "      <td>1.764624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.841385</td>\n",
       "      <td>1.203848</td>\n",
       "      <td>1.015360</td>\n",
       "      <td>2.289634</td>\n",
       "      <td>3.108612</td>\n",
       "      <td>3.066139</td>\n",
       "      <td>3.410717</td>\n",
       "      <td>3.487736</td>\n",
       "      <td>3.641201</td>\n",
       "      <td>3.664932</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.717421</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.135737</td>\n",
       "      <td>3.021475</td>\n",
       "      <td>2.054345</td>\n",
       "      <td>2.601995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.541554</td>\n",
       "      <td>2.089870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.904243</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.701741</td>\n",
       "      <td>2.048752</td>\n",
       "      <td>3.429904</td>\n",
       "      <td>3.443864</td>\n",
       "      <td>3.630035</td>\n",
       "      <td>3.447663</td>\n",
       "      <td>3.543115</td>\n",
       "      <td>3.584522</td>\n",
       "      <td>...</td>\n",
       "      <td>1.782716</td>\n",
       "      <td>1.672929</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.321039</td>\n",
       "      <td>2.814061</td>\n",
       "      <td>1.831230</td>\n",
       "      <td>2.752087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.796713</td>\n",
       "      <td>2.131137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.879258</td>\n",
       "      <td>1.067815</td>\n",
       "      <td>1.554852</td>\n",
       "      <td>1.872739</td>\n",
       "      <td>3.256246</td>\n",
       "      <td>3.224574</td>\n",
       "      <td>3.414243</td>\n",
       "      <td>3.511133</td>\n",
       "      <td>3.631307</td>\n",
       "      <td>3.591646</td>\n",
       "      <td>...</td>\n",
       "      <td>1.976717</td>\n",
       "      <td>1.592288</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.984032</td>\n",
       "      <td>2.875709</td>\n",
       "      <td>1.361350</td>\n",
       "      <td>2.587857</td>\n",
       "      <td>2.151186</td>\n",
       "      <td>2.360025</td>\n",
       "      <td>1.863263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.898461</td>\n",
       "      <td>1.542078</td>\n",
       "      <td>1.566437</td>\n",
       "      <td>2.291125</td>\n",
       "      <td>3.365076</td>\n",
       "      <td>3.487488</td>\n",
       "      <td>3.659641</td>\n",
       "      <td>3.380352</td>\n",
       "      <td>3.512384</td>\n",
       "      <td>3.640448</td>\n",
       "      <td>...</td>\n",
       "      <td>1.996030</td>\n",
       "      <td>1.791971</td>\n",
       "      <td>1.832317</td>\n",
       "      <td>2.228862</td>\n",
       "      <td>2.857839</td>\n",
       "      <td>2.049761</td>\n",
       "      <td>2.583754</td>\n",
       "      <td>2.359171</td>\n",
       "      <td>2.233985</td>\n",
       "      <td>2.094087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.861195</td>\n",
       "      <td>2.333064</td>\n",
       "      <td>2.299202</td>\n",
       "      <td>2.626987</td>\n",
       "      <td>3.400348</td>\n",
       "      <td>3.366804</td>\n",
       "      <td>3.525154</td>\n",
       "      <td>3.597381</td>\n",
       "      <td>3.686170</td>\n",
       "      <td>3.677235</td>\n",
       "      <td>...</td>\n",
       "      <td>1.617420</td>\n",
       "      <td>1.768268</td>\n",
       "      <td>1.081707</td>\n",
       "      <td>2.042339</td>\n",
       "      <td>3.166306</td>\n",
       "      <td>2.073095</td>\n",
       "      <td>2.505313</td>\n",
       "      <td>2.013553</td>\n",
       "      <td>2.916849</td>\n",
       "      <td>2.080482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.921344</td>\n",
       "      <td>2.051538</td>\n",
       "      <td>2.068779</td>\n",
       "      <td>2.452139</td>\n",
       "      <td>3.332721</td>\n",
       "      <td>3.313979</td>\n",
       "      <td>3.492541</td>\n",
       "      <td>3.221477</td>\n",
       "      <td>3.240557</td>\n",
       "      <td>3.379784</td>\n",
       "      <td>...</td>\n",
       "      <td>2.151891</td>\n",
       "      <td>2.089940</td>\n",
       "      <td>1.738622</td>\n",
       "      <td>2.150050</td>\n",
       "      <td>2.619417</td>\n",
       "      <td>2.191814</td>\n",
       "      <td>2.779236</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.071182</td>\n",
       "      <td>2.332014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.820743</td>\n",
       "      <td>2.371327</td>\n",
       "      <td>2.291091</td>\n",
       "      <td>2.770775</td>\n",
       "      <td>3.501755</td>\n",
       "      <td>3.524519</td>\n",
       "      <td>3.560045</td>\n",
       "      <td>3.539958</td>\n",
       "      <td>3.672477</td>\n",
       "      <td>3.595527</td>\n",
       "      <td>...</td>\n",
       "      <td>1.384980</td>\n",
       "      <td>1.397853</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.214314</td>\n",
       "      <td>3.211612</td>\n",
       "      <td>1.898698</td>\n",
       "      <td>2.455066</td>\n",
       "      <td>1.867850</td>\n",
       "      <td>2.832685</td>\n",
       "      <td>1.770852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.895507</td>\n",
       "      <td>2.153022</td>\n",
       "      <td>1.991226</td>\n",
       "      <td>2.585043</td>\n",
       "      <td>3.592847</td>\n",
       "      <td>3.663589</td>\n",
       "      <td>3.684571</td>\n",
       "      <td>3.623747</td>\n",
       "      <td>3.696136</td>\n",
       "      <td>3.725038</td>\n",
       "      <td>...</td>\n",
       "      <td>1.350442</td>\n",
       "      <td>1.416641</td>\n",
       "      <td>1.512551</td>\n",
       "      <td>2.350752</td>\n",
       "      <td>3.419290</td>\n",
       "      <td>1.722963</td>\n",
       "      <td>2.401245</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.831134</td>\n",
       "      <td>2.041314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.814212</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.526598</td>\n",
       "      <td>2.389042</td>\n",
       "      <td>3.595472</td>\n",
       "      <td>3.613147</td>\n",
       "      <td>3.663301</td>\n",
       "      <td>3.514882</td>\n",
       "      <td>3.665123</td>\n",
       "      <td>3.636483</td>\n",
       "      <td>...</td>\n",
       "      <td>1.763203</td>\n",
       "      <td>1.561101</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.003116</td>\n",
       "      <td>3.343265</td>\n",
       "      <td>1.856970</td>\n",
       "      <td>2.621716</td>\n",
       "      <td>1.310693</td>\n",
       "      <td>2.586013</td>\n",
       "      <td>1.803184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.868812</td>\n",
       "      <td>1.646306</td>\n",
       "      <td>1.644636</td>\n",
       "      <td>2.181086</td>\n",
       "      <td>3.153080</td>\n",
       "      <td>3.164950</td>\n",
       "      <td>3.434115</td>\n",
       "      <td>3.444213</td>\n",
       "      <td>3.570820</td>\n",
       "      <td>3.639826</td>\n",
       "      <td>...</td>\n",
       "      <td>1.836039</td>\n",
       "      <td>1.842703</td>\n",
       "      <td>1.167170</td>\n",
       "      <td>2.024650</td>\n",
       "      <td>3.120689</td>\n",
       "      <td>1.967454</td>\n",
       "      <td>2.575978</td>\n",
       "      <td>2.144870</td>\n",
       "      <td>2.315708</td>\n",
       "      <td>2.014814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.863111</td>\n",
       "      <td>2.300726</td>\n",
       "      <td>2.301008</td>\n",
       "      <td>2.763630</td>\n",
       "      <td>3.433169</td>\n",
       "      <td>3.435089</td>\n",
       "      <td>3.537763</td>\n",
       "      <td>3.490465</td>\n",
       "      <td>3.608122</td>\n",
       "      <td>3.660884</td>\n",
       "      <td>...</td>\n",
       "      <td>1.810300</td>\n",
       "      <td>1.735319</td>\n",
       "      <td>1.676511</td>\n",
       "      <td>2.258913</td>\n",
       "      <td>3.289366</td>\n",
       "      <td>1.830973</td>\n",
       "      <td>2.543944</td>\n",
       "      <td>1.703076</td>\n",
       "      <td>2.695149</td>\n",
       "      <td>2.036848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.809824</td>\n",
       "      <td>2.272746</td>\n",
       "      <td>2.135005</td>\n",
       "      <td>2.619771</td>\n",
       "      <td>3.310107</td>\n",
       "      <td>3.168209</td>\n",
       "      <td>3.409158</td>\n",
       "      <td>3.576675</td>\n",
       "      <td>3.693858</td>\n",
       "      <td>3.616255</td>\n",
       "      <td>...</td>\n",
       "      <td>1.134496</td>\n",
       "      <td>1.565021</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.247359</td>\n",
       "      <td>3.145498</td>\n",
       "      <td>1.739889</td>\n",
       "      <td>2.465056</td>\n",
       "      <td>2.409172</td>\n",
       "      <td>2.806560</td>\n",
       "      <td>1.834166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.933567</td>\n",
       "      <td>1.750277</td>\n",
       "      <td>1.897242</td>\n",
       "      <td>2.223002</td>\n",
       "      <td>3.384309</td>\n",
       "      <td>3.440791</td>\n",
       "      <td>3.578622</td>\n",
       "      <td>3.380562</td>\n",
       "      <td>3.517615</td>\n",
       "      <td>3.552477</td>\n",
       "      <td>...</td>\n",
       "      <td>2.153388</td>\n",
       "      <td>2.253241</td>\n",
       "      <td>1.798858</td>\n",
       "      <td>2.316599</td>\n",
       "      <td>2.983811</td>\n",
       "      <td>1.949048</td>\n",
       "      <td>2.781030</td>\n",
       "      <td>2.052925</td>\n",
       "      <td>2.039890</td>\n",
       "      <td>2.374418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.850494</td>\n",
       "      <td>2.422114</td>\n",
       "      <td>2.405107</td>\n",
       "      <td>2.939859</td>\n",
       "      <td>3.596283</td>\n",
       "      <td>3.509580</td>\n",
       "      <td>3.548588</td>\n",
       "      <td>3.607209</td>\n",
       "      <td>3.701704</td>\n",
       "      <td>3.645704</td>\n",
       "      <td>...</td>\n",
       "      <td>2.136879</td>\n",
       "      <td>1.864985</td>\n",
       "      <td>1.670802</td>\n",
       "      <td>2.279279</td>\n",
       "      <td>3.299403</td>\n",
       "      <td>2.205123</td>\n",
       "      <td>2.654013</td>\n",
       "      <td>1.427648</td>\n",
       "      <td>2.889845</td>\n",
       "      <td>2.028653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.845383</td>\n",
       "      <td>2.148819</td>\n",
       "      <td>2.104453</td>\n",
       "      <td>2.713087</td>\n",
       "      <td>3.262192</td>\n",
       "      <td>3.195509</td>\n",
       "      <td>3.447792</td>\n",
       "      <td>3.278127</td>\n",
       "      <td>3.475588</td>\n",
       "      <td>3.678231</td>\n",
       "      <td>...</td>\n",
       "      <td>1.962275</td>\n",
       "      <td>1.629206</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.266467</td>\n",
       "      <td>3.209866</td>\n",
       "      <td>1.735519</td>\n",
       "      <td>2.592343</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.468259</td>\n",
       "      <td>2.088632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 3312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6     \\\n",
       "0   3.824254  1.923762  1.918450  2.352067  3.117298  3.051735  3.307977   \n",
       "1   3.904190  2.309524  2.152930  2.439439  3.532368  3.524866  3.677791   \n",
       "2   3.750908  1.161068  1.017033  2.347993  3.381889  3.393096  3.509134   \n",
       "3   3.809383  1.912355  1.856940  2.498944  3.289406  3.371232  3.541995   \n",
       "4   3.893561  2.094192  1.881271  2.785707  3.344339  3.274417  3.485872   \n",
       "5   3.841385  1.203848  1.015360  2.289634  3.108612  3.066139  3.410717   \n",
       "6   3.904243  1.000000  1.701741  2.048752  3.429904  3.443864  3.630035   \n",
       "7   3.879258  1.067815  1.554852  1.872739  3.256246  3.224574  3.414243   \n",
       "8   3.898461  1.542078  1.566437  2.291125  3.365076  3.487488  3.659641   \n",
       "9   3.861195  2.333064  2.299202  2.626987  3.400348  3.366804  3.525154   \n",
       "10  3.921344  2.051538  2.068779  2.452139  3.332721  3.313979  3.492541   \n",
       "11  3.820743  2.371327  2.291091  2.770775  3.501755  3.524519  3.560045   \n",
       "12  3.895507  2.153022  1.991226  2.585043  3.592847  3.663589  3.684571   \n",
       "13  3.814212  1.000000  1.526598  2.389042  3.595472  3.613147  3.663301   \n",
       "14  3.868812  1.646306  1.644636  2.181086  3.153080  3.164950  3.434115   \n",
       "15  3.863111  2.300726  2.301008  2.763630  3.433169  3.435089  3.537763   \n",
       "16  3.809824  2.272746  2.135005  2.619771  3.310107  3.168209  3.409158   \n",
       "17  3.933567  1.750277  1.897242  2.223002  3.384309  3.440791  3.578622   \n",
       "18  3.850494  2.422114  2.405107  2.939859  3.596283  3.509580  3.548588   \n",
       "19  3.845383  2.148819  2.104453  2.713087  3.262192  3.195509  3.447792   \n",
       "\n",
       "        7         8         9     ...      3302      3303      3304      3305  \\\n",
       "0   3.430222  3.586667  3.605218  ...  1.836830  1.855640  1.142389  2.054345   \n",
       "1   3.636671  3.696868  3.716764  ...  1.951532  1.442323  1.000000  2.127914   \n",
       "2   3.512466  3.622203  3.603050  ...  1.000000  1.584105  1.000000  1.945321   \n",
       "3   3.498470  3.473179  3.628930  ...  1.869965  1.481658  1.000000  2.155032   \n",
       "4   3.516527  3.642358  3.688235  ...  1.480725  1.510545  1.000000  2.094192   \n",
       "5   3.487736  3.641201  3.664932  ...  1.000000  1.717421  1.000000  2.135737   \n",
       "6   3.447663  3.543115  3.584522  ...  1.782716  1.672929  1.000000  2.321039   \n",
       "7   3.511133  3.631307  3.591646  ...  1.976717  1.592288  1.000000  1.984032   \n",
       "8   3.380352  3.512384  3.640448  ...  1.996030  1.791971  1.832317  2.228862   \n",
       "9   3.597381  3.686170  3.677235  ...  1.617420  1.768268  1.081707  2.042339   \n",
       "10  3.221477  3.240557  3.379784  ...  2.151891  2.089940  1.738622  2.150050   \n",
       "11  3.539958  3.672477  3.595527  ...  1.384980  1.397853  1.000000  2.214314   \n",
       "12  3.623747  3.696136  3.725038  ...  1.350442  1.416641  1.512551  2.350752   \n",
       "13  3.514882  3.665123  3.636483  ...  1.763203  1.561101  1.000000  2.003116   \n",
       "14  3.444213  3.570820  3.639826  ...  1.836039  1.842703  1.167170  2.024650   \n",
       "15  3.490465  3.608122  3.660884  ...  1.810300  1.735319  1.676511  2.258913   \n",
       "16  3.576675  3.693858  3.616255  ...  1.134496  1.565021  1.000000  2.247359   \n",
       "17  3.380562  3.517615  3.552477  ...  2.153388  2.253241  1.798858  2.316599   \n",
       "18  3.607209  3.701704  3.645704  ...  2.136879  1.864985  1.670802  2.279279   \n",
       "19  3.278127  3.475588  3.678231  ...  1.962275  1.629206  1.000000  2.266467   \n",
       "\n",
       "        3306      3307      3308      3309      3310      3311  \n",
       "0   2.808224  1.782186  2.665703  2.468214  2.478581  2.308842  \n",
       "1   2.979658  1.961089  2.519027  2.054383  2.689903  2.090928  \n",
       "2   3.257004  1.965061  2.536066  1.449324  2.605230  1.368659  \n",
       "3   3.270371  1.928473  2.618074  2.154013  2.530046  2.185514  \n",
       "4   3.246666  1.824516  2.562317  1.942256  2.598517  1.764624  \n",
       "5   3.021475  2.054345  2.601995  1.000000  2.541554  2.089870  \n",
       "6   2.814061  1.831230  2.752087  1.000000  1.796713  2.131137  \n",
       "7   2.875709  1.361350  2.587857  2.151186  2.360025  1.863263  \n",
       "8   2.857839  2.049761  2.583754  2.359171  2.233985  2.094087  \n",
       "9   3.166306  2.073095  2.505313  2.013553  2.916849  2.080482  \n",
       "10  2.619417  2.191814  2.779236  1.000000  2.071182  2.332014  \n",
       "11  3.211612  1.898698  2.455066  1.867850  2.832685  1.770852  \n",
       "12  3.419290  1.722963  2.401245  1.000000  2.831134  2.041314  \n",
       "13  3.343265  1.856970  2.621716  1.310693  2.586013  1.803184  \n",
       "14  3.120689  1.967454  2.575978  2.144870  2.315708  2.014814  \n",
       "15  3.289366  1.830973  2.543944  1.703076  2.695149  2.036848  \n",
       "16  3.145498  1.739889  2.465056  2.409172  2.806560  1.834166  \n",
       "17  2.983811  1.949048  2.781030  2.052925  2.039890  2.374418  \n",
       "18  3.299403  2.205123  2.654013  1.427648  2.889845  2.028653  \n",
       "19  3.209866  1.735519  2.592343  1.000000  2.468259  2.088632  \n",
       "\n",
       "[20 rows x 3312 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_3.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(new_3)\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>principal component 1</th>\n",
       "      <th>principal component 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.956033</td>\n",
       "      <td>5.010587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.652713</td>\n",
       "      <td>1.986769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-6.773345</td>\n",
       "      <td>7.977499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.605792</td>\n",
       "      <td>-4.360893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.723806</td>\n",
       "      <td>0.069014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   principal component 1  principal component 2\n",
       "0              -1.956033               5.010587\n",
       "1              -5.652713               1.986769\n",
       "2              -6.773345               7.977499\n",
       "3              -0.605792              -4.360893\n",
       "4              -6.723806               0.069014"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "principalDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDf = pd.concat([principalDf, new_3[[3311]]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new3_centered = new_3 - new_3.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, s, vt = np.linalg.svd(new3_centered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = vt.T[:, 0]\n",
    "c2 = vt.T[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2 = vt.T[:, :2]\n",
    "x2d = new3_centered.dot(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.95)\n",
    "new3_reduced = pca.fit_transform(new3_centered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9505844014343138"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "label1 = pd.read_csv(\"Dataset/TrainLabel1.txt\", header= None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  1\n",
       "1  1\n",
       "2  2\n",
       "3  1\n",
       "4  1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(new3_reduced,label1,test_size=0.25,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train,y_train)\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf = LogisticRegression(C=1.1)\n",
    "# C=1.0,1.1,1.2\n",
    "rnd_clf = RandomForestClassifier(n_estimators=10)\n",
    "# n_estimators=10,20,100\n",
    "svm_clf = SVC(kernel='linear')\n",
    "# kernel = 'linear', 'rbf','poly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              LogisticRegression(C=1.1, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='warn',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=None,\n",
       "                                                 solver='warn', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False)),\n",
       "                             ('rf',\n",
       "                              RandomForestClassifier(bootstrap=True,\n",
       "                                                     class_weight=None,\n",
       "                                                     criterion='gini',...\n",
       "                                                     oob_score=False,\n",
       "                                                     random_state=None,\n",
       "                                                     verbose=0,\n",
       "                                                     warm_start=False)),\n",
       "                             ('svc',\n",
       "                              SVC(C=1.0, cache_size=200, class_weight=None,\n",
       "                                  coef0=0.0, decision_function_shape='ovr',\n",
       "                                  degree=3, gamma='auto_deprecated',\n",
       "                                  kernel='linear', max_iter=-1,\n",
       "                                  probability=False, random_state=None,\n",
       "                                  shrinking=True, tol=0.001, verbose=False))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(estimators=[('lr', log_clf),('rf',rnd_clf),('svc',svm_clf)],voting='hard')\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf_y_pred = log_clf.predict(X_test)\n",
    "rnd_clf_y_pred = log_clf.predict(X_test)\n",
    "svm_clf_y_pred = log_clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision logical regression: 0.8933270676691729\n",
      "precision randon fores:  0.8933270676691729\n",
      "precision svm:  0.8933270676691729\n"
     ]
    }
   ],
   "source": [
    "print(\"precision logical regression:\",precision_score(y_test,log_clf_y_pred, average='weighted'))\n",
    "print(\"precision randon fores: \",precision_score(y_test,rnd_clf_y_pred, average='weighted'))\n",
    "print(\"precision svm: \",precision_score(y_test,svm_clf_y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall logicaal regression:  0.8421052631578947\n",
      "recall random forest:  0.8421052631578947\n",
      "recall svm:  0.8421052631578947\n"
     ]
    }
   ],
   "source": [
    "print(\"recall logicaal regression: \",recall_score(y_test,log_clf_y_pred, average='weighted'))\n",
    "print(\"recall random forest: \",recall_score(y_test,rnd_clf_y_pred, average='weighted'))\n",
    "print(\"recall svm: \",recall_score(y_test,svm_clf_y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.8421052631578947\n",
      "RandomForestClassifier 0.7105263157894737\n",
      "SVC 0.9210526315789473\n",
      "VotingClassifier 0.9210526315789473\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (log_clf,rnd_clf,svm_clf, voting_clf):\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    print(clf.__class__.__name__,accuracy_score(y_test, y_pred))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_knn_clf=knn_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy knn:  0.8947368421052632\n",
      "precision knn:  0.8788798920377868\n",
      "recall knn:  0.8947368421052632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy knn: \",accuracy_score(y_test, y_pred_knn_clf))\n",
    "print(\"precision knn: \",precision_score(y_test,y_pred_knn_clf, average='weighted'))\n",
    "print(\"recall knn: \",recall_score(y_test,y_pred_knn_clf, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=10, random_state=42, shuffle=False)\n",
    "#n_splits = 3,5,10\n",
    "best_svr = SVC(kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Index:  [ 15  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32\n",
      "  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50\n",
      "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68\n",
      "  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86\n",
      "  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104\n",
      " 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122\n",
      " 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149] \n",
      "\n",
      "Test Index:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "Train Index:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  30  31  32\n",
      "  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50\n",
      "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68\n",
      "  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86\n",
      "  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104\n",
      " 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122\n",
      " 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149] \n",
      "\n",
      "Test Index:  [15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "Train Index:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  45  46  47  48  49  50\n",
      "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68\n",
      "  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86\n",
      "  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104\n",
      " 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122\n",
      " 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149] \n",
      "\n",
      "Test Index:  [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]\n",
      "Train Index:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  60  61  62  63  64  65  66  67  68\n",
      "  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86\n",
      "  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104\n",
      " 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122\n",
      " 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149] \n",
      "\n",
      "Test Index:  [45 46 47 48 49 50 51 52 53 54 55 56 57 58 59]\n",
      "Train Index:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  75  76  77  78  79  80  81  82  83  84  85  86\n",
      "  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104\n",
      " 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122\n",
      " 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149] \n",
      "\n",
      "Test Index:  [60 61 62 63 64 65 66 67 68 69 70 71 72 73 74]\n",
      "Train Index:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104\n",
      " 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122\n",
      " 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149] \n",
      "\n",
      "Test Index:  [75 76 77 78 79 80 81 82 83 84 85 86 87 88 89]\n",
      "Train Index:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      " 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122\n",
      " 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149] \n",
      "\n",
      "Test Index:  [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104]\n",
      "Train Index:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 120 121 122\n",
      " 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149] \n",
      "\n",
      "Test Index:  [105 106 107 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "Train Index:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 135 136 137 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149] \n",
      "\n",
      "Test Index:  [120 121 122 123 124 125 126 127 128 129 130 131 132 133 134]\n",
      "Train Index:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134] \n",
      "\n",
      "Test Index:  [135 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in cv.split(new3_reduced):\n",
    "    print(\"Train Index: \", train_index, \"\\n\")\n",
    "    print(\"Test Index: \", test_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_best_svr = best_svr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy kfold:  0.7368421052631579\n",
      "precision kfold:  0.5773993808049536\n",
      "recall kfold:  0.7368421052631579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy kfold: \",accuracy_score(y_test, y_pred_best_svr))\n",
    "print(\"precision kfold: \",precision_score(y_test,y_pred_best_svr, average='weighted'))\n",
    "print(\"recall kfold: \",recall_score(y_test,y_pred_best_svr, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "    return roc_auc_score(y_test, y_pred, average=average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score logical regression:  0.956991341991342\n",
      "roc_auc_score random forest:  0.956991341991342\n",
      "roc_auc_score svm: 0.956991341991342\n",
      "roc_auc_score knn: 0.8313744588744589\n",
      "roc_auc_score kfold: 0.6085714285714285\n"
     ]
    }
   ],
   "source": [
    "print(\"roc_auc_score logical regression: \",multiclass_roc_auc_score(y_test, log_clf_y_pred))\n",
    "print(\"roc_auc_score random forest: \",multiclass_roc_auc_score(y_test, rnd_clf_y_pred))\n",
    "print(\"roc_auc_score svm:\",multiclass_roc_auc_score(y_test, svm_clf_y_pred))\n",
    "print(\"roc_auc_score knn:\",multiclass_roc_auc_score(y_test, y_pred_knn_clf))\n",
    "print(\"roc_auc_score kfold:\",multiclass_roc_auc_score(y_test, y_pred_best_svr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = pd.read_csv(\"Dataset/TrainData1.txt\", header= None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3302</th>\n",
       "      <th>3303</th>\n",
       "      <th>3304</th>\n",
       "      <th>3305</th>\n",
       "      <th>3306</th>\n",
       "      <th>3307</th>\n",
       "      <th>3308</th>\n",
       "      <th>3309</th>\n",
       "      <th>3310</th>\n",
       "      <th>3311</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.824254</td>\n",
       "      <td>1.923762</td>\n",
       "      <td>1.918450</td>\n",
       "      <td>2.352067e+00</td>\n",
       "      <td>3.117298</td>\n",
       "      <td>3.051735</td>\n",
       "      <td>3.307977</td>\n",
       "      <td>3.430222e+00</td>\n",
       "      <td>3.586667</td>\n",
       "      <td>3.605218</td>\n",
       "      <td>...</td>\n",
       "      <td>1.836830</td>\n",
       "      <td>1.855640</td>\n",
       "      <td>1.142389</td>\n",
       "      <td>2.054345</td>\n",
       "      <td>2.808224</td>\n",
       "      <td>1.782186</td>\n",
       "      <td>2.665703</td>\n",
       "      <td>2.468214</td>\n",
       "      <td>2.478581</td>\n",
       "      <td>2.308842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.904190</td>\n",
       "      <td>2.309524</td>\n",
       "      <td>2.152930</td>\n",
       "      <td>1.000000e+99</td>\n",
       "      <td>3.532368</td>\n",
       "      <td>3.524866</td>\n",
       "      <td>3.677791</td>\n",
       "      <td>3.636671e+00</td>\n",
       "      <td>3.696868</td>\n",
       "      <td>3.716764</td>\n",
       "      <td>...</td>\n",
       "      <td>1.951532</td>\n",
       "      <td>1.442323</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.127914</td>\n",
       "      <td>2.979658</td>\n",
       "      <td>1.961089</td>\n",
       "      <td>2.519027</td>\n",
       "      <td>2.054383</td>\n",
       "      <td>2.689903</td>\n",
       "      <td>2.090928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.750908</td>\n",
       "      <td>1.161068</td>\n",
       "      <td>1.017033</td>\n",
       "      <td>2.347993e+00</td>\n",
       "      <td>3.381889</td>\n",
       "      <td>3.393096</td>\n",
       "      <td>3.509134</td>\n",
       "      <td>3.512466e+00</td>\n",
       "      <td>3.622203</td>\n",
       "      <td>3.603050</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.584105</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.945321</td>\n",
       "      <td>3.257004</td>\n",
       "      <td>1.965061</td>\n",
       "      <td>2.536066</td>\n",
       "      <td>1.449324</td>\n",
       "      <td>2.605230</td>\n",
       "      <td>1.368659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.809383</td>\n",
       "      <td>1.912355</td>\n",
       "      <td>1.856940</td>\n",
       "      <td>2.498944e+00</td>\n",
       "      <td>3.289406</td>\n",
       "      <td>3.371232</td>\n",
       "      <td>3.541995</td>\n",
       "      <td>1.000000e+99</td>\n",
       "      <td>3.473179</td>\n",
       "      <td>3.628930</td>\n",
       "      <td>...</td>\n",
       "      <td>1.869965</td>\n",
       "      <td>1.481658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.155032</td>\n",
       "      <td>3.270371</td>\n",
       "      <td>1.928473</td>\n",
       "      <td>2.618074</td>\n",
       "      <td>2.154013</td>\n",
       "      <td>2.530046</td>\n",
       "      <td>2.185514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.893561</td>\n",
       "      <td>2.094192</td>\n",
       "      <td>1.881271</td>\n",
       "      <td>2.785707e+00</td>\n",
       "      <td>3.344339</td>\n",
       "      <td>3.274417</td>\n",
       "      <td>3.485872</td>\n",
       "      <td>3.516527e+00</td>\n",
       "      <td>3.642358</td>\n",
       "      <td>3.688235</td>\n",
       "      <td>...</td>\n",
       "      <td>1.480725</td>\n",
       "      <td>1.510545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.094192</td>\n",
       "      <td>3.246666</td>\n",
       "      <td>1.824516</td>\n",
       "      <td>2.562317</td>\n",
       "      <td>1.942256</td>\n",
       "      <td>2.598517</td>\n",
       "      <td>1.764624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2             3         4         5         6     \\\n",
       "0  3.824254  1.923762  1.918450  2.352067e+00  3.117298  3.051735  3.307977   \n",
       "1  3.904190  2.309524  2.152930  1.000000e+99  3.532368  3.524866  3.677791   \n",
       "2  3.750908  1.161068  1.017033  2.347993e+00  3.381889  3.393096  3.509134   \n",
       "3  3.809383  1.912355  1.856940  2.498944e+00  3.289406  3.371232  3.541995   \n",
       "4  3.893561  2.094192  1.881271  2.785707e+00  3.344339  3.274417  3.485872   \n",
       "\n",
       "           7         8         9     ...      3302      3303      3304  \\\n",
       "0  3.430222e+00  3.586667  3.605218  ...  1.836830  1.855640  1.142389   \n",
       "1  3.636671e+00  3.696868  3.716764  ...  1.951532  1.442323  1.000000   \n",
       "2  3.512466e+00  3.622203  3.603050  ...  1.000000  1.584105  1.000000   \n",
       "3  1.000000e+99  3.473179  3.628930  ...  1.869965  1.481658  1.000000   \n",
       "4  3.516527e+00  3.642358  3.688235  ...  1.480725  1.510545  1.000000   \n",
       "\n",
       "       3305      3306      3307      3308      3309      3310      3311  \n",
       "0  2.054345  2.808224  1.782186  2.665703  2.468214  2.478581  2.308842  \n",
       "1  2.127914  2.979658  1.961089  2.519027  2.054383  2.689903  2.090928  \n",
       "2  1.945321  3.257004  1.965061  2.536066  1.449324  2.605230  1.368659  \n",
       "3  2.155032  3.270371  1.928473  2.618074  2.154013  2.530046  2.185514  \n",
       "4  2.094192  3.246666  1.824516  2.562317  1.942256  2.598517  1.764624  \n",
       "\n",
       "[5 rows x 3312 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
